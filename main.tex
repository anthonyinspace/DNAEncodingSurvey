\documentclass{bioinfo}
\copyrightyear{2015} \pubyear{2015}

\access{Advance Access Publication Date: Day Month Year}
\appnotes{Manuscript Category}

% Related work comparison table
\usepackage{amsmath,wasysym} % \CIRCLE, \Circle
\usepackage{multirow} % \multirow
\usepackage{times} % font in table header

\begin{document}
\firstpage{1}

\subtitle{Sequence Analysis}

\title{Hiding Data in Cellular DNA: Contextualizing Diverse Encoding Schemes}
\author[Sample \textit{et~al}.]{Anthony P. Machado\,$^{\text{\sfb 1,}*}$, Gaby G. Dagher\,$^{\text{\sfb 2}}$ and Eddie C. Davis\,$^{\text{\sfb 2,}*}$}
\address{$^{\text{\sf 1}}$Computer Science Department, Boise State University, Boise, 83725, USA}

\corresp{$^\ast$To whom correspondence should be addressed.}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\abstract{\textbf{Motivation:} DNA, the macromolecule used by organisms to store and transmit genomic data, has attracted the attention of privacy researchers as a channel for secure data transfer. DNA's small size and abundance in nature makes it an ideal steganographic medium for hiding messages. Already, artificially synthesized DNA has been used to store text, audio, and images. Encoded cellular DNA is not far behind, with much research being done on ways to safely embed data without harming the cell.\\
\textbf{Results:} In this survey we provide the first systematic comparison of cellular encoding schemes proposed in the literature. Different DNA regions in the cell have their own unique bio-restrictions that must be satisfied for DNA storage. Drawing from a wide array of schemes, we compare the novel techniques used to meet these bio-restrictions. This contextualization of the research creates a bigger picture that can help guide the design of future schemes. We also survey the compression methods and error detection techniques used by the encoding schemes, and their effect on error rate and bits-per-base density. Finally, we propose future directions for research in untapped cellular regions such as mitochondrial DNA and we offer novel insights into the potential for epigenetic encoding with methylation and histones. \\
\textbf{Contact:} \href{anthonymachado@u.boisestate.edu}{anthonymachado@u.boisestate.edu}\\
\textbf{Supplementary information:} Supplementary data are available at \textit{Bioinformatics}
online.}

\maketitle

\section{Introduction}

Biosteganography is an emerging field in privacy research that combines techniques from genetic engineering, bioinformatics, cryptography and forensics to secretly transfer data within a living cell's DNA~\cite{B2016JOB}. Data ranging from simple text messages to audio recordings and color images can be inserted into cellular DNA for secure transmission. Because DNA is information dense and occurs abundantly in nature, it makes an ideal medium for sending messages secretly. Basic steganographic principles dictate that if an attacker doesn’t know where to find a confidential message in the first place, the message is far more secure~\cite{A2001IEEEIC}. Locating encoded DNA would be harder than finding a needle in a haystack. A needle, at least, can be seen by the human eye.

Traditional digital storage systems such as hard drives and SD cards have detectable emanations, which makes them vulnerable to side attacks~\cite{T2008TOIAS}. Modified DNA, however, has no measurable emanations. If an agent needed to carry a confidential message through a tight security checkpoint, any form of electronic storage could be easily detected, while physical recordings like paper or tape could be visibly located by the security guard. A DNA encoded message, however, located in the cells of the agent's thumb, or in bacteria under the agent's nail, could be brought through without detection. The receiver of the message would need to know how to decode the data, and have the lab equipment to amplify and sequence the DNA in order to retrieve the message.

Inserting hidden data into DNA is also crucial for watermarking patented genes. Advances in gene editing technology have led to a rise in genetically modified organisms being developed in a variety of sectors such as agriculture, healthcare, and energy. For added security of these novel genomes, many companies have begun embedding hidden watermarks in their DNA so that ownership can be established in the case of theft. For this purpose too, secrecy is essential. The watermark must be embedded in such a way that the thief cannot find it, else the thief would simply remove it. Thus, biosteganography is an overlapping goal both of individuals wanting to send data privately and companies wanting to watermark genetic inventions.

Many encoding schemes have been proposed to accomplish data embedding in cellular DNA.

In this survey, we will provide the first systematic analysis of these diverse encoding schemes, in which:
\begin{itemize}
\item We define the unique bio-restrictions associated with cellular encoding and compare how the proposed encoding schemes meet these restrictions;
\item We contrast the error rates and bits-per-nucleotide densities of each of the schemes, highlighting the effects of error correction and compression techniques on both; and
\item We propose new directions for research incorporating novel epigenetic techniques.
\end{itemize}

The rest of the survey is organized as follows. In Section 2 we provide a background on genetics, explain techniques in artificial DNA encoding, and clarify the biological restrictions involved in cellular encoding. A systematic comparison of the encoding schemes for coding and non-coding regions is presented in Section 3, in which we look at how each encoding scheme meets cellular restrictions and the error rate and bits-per-nucleotide density it offers. Finally, in Section we propose new directions for future encoding schemes that use epigenetics and alternative genetic regions.

%\enlargethispage{12pt}

\section{Background}

\subsection{DNA}

Every living cell contains DNA molecules encoded with instructions for making the proteins necessary for the cell to function. DNA takes the form of a double helix made of two antiparallel strands. Each strand is composed of a sequence of 4 nucleotides: adenine (A), guanine (G), cytosine (C), and thymine (T). The purines adenine and guanine, and the pyrimidines cytosine and thymine, form hydrogen bonds with each other across the double helix. Adenine binds to thymine with two hydrogen bonds, and guanine binds to cytosine with three. Every three nucleotides forms a codon that the cell reads and processes to create an amino acid, the building block of a protein~\cite{WC1953N}. Proteins can be encoded on either strand.

There are only 20 amino acids, despite the fact that $4^3$ = 64 possible codon variations exist. This is because many amino acids are correlated with up to five redundant codons. Also, three codons are used specifically as stop signals to indicate the end of a protein chain. The redundancy in codon to amino acid mapping is called codon degeneracy~\cite{WBBGLL2008}. Codon degeneracy gives an evolutionary advantage to the cell by allowing certain mutations to occur in a codon while preserving the codon’s functionality.

\begin{table}[t]
	\caption{Codons}
	\label{fig:table1}
	\scalebox{.85}{
 \begin{tabular}{||c || c c c c c c||}
 \hline
 Amino & & & Codons & & &\\ [0.5ex]
 Acids & & & & & &\\ [0.5ex]
 \hline\hline
 Ala & GCT & GCC & GCA & GCG & &\\
 \hline
 Arg & CGT & CGC & CGA & CGG & AGA & AGG \\
 \hline
 Asn & AAT & AAC & & & &\\
 \hline
 Asp & GAT & GAC & & & &\\
 \hline
 Cys & TGT & TGC & & & &\\
 \hline
 Gln & CAA & CAG & & & &\\
 \hline
 Glu & GAA & GAG & & & &\\
 \hline
 Gly & GGT & GGC & GGA & GGG & &\\
 \hline
 His & CAT & CAC & & & &\\
 \hline
 Ile & ATT & ATC & ATA & & &\\
 \hline
 Leu & TTA & TTG & CTT & CTC & CTA & CTG \\
 \hline
 Lys & AAA & AAG & & & &\\
 \hline
 Met & ATG & & & & &\\
 \hline
 Phe & TTT & TTC & & & &\\
 \hline
 Pro & CCT & CCC & CCA & CCG & &\\
 \hline
 Ser & TCT & TCC & TCA & TCG & AGT & AGC \\
 \hline
 Thr & ACT & ACC & ACA & ACG & &\\
 \hline
 Trp & TGG & & & & &\\
 \hline
 Tyr & TAT & TAC & & & &\\
 \hline
 Val & GTT & GTC & GTA & GTG & &\\
 \hline
 START & ATG & & & & &\\
 \hline
 STOP & TAA & TGA & TAG & & &\\[1ex]
 \hline
\end{tabular}}
\end{table}

\section{Compression and Error Correction}

Smith et al.~\cite{SFHC2003BL} were the first to suggest a data compression technique in DNA encoding, specifically the Huffman Code. The Huffman Code is a form of lossless data compression that forms a symbol table using fewer bits to encode more common characters~\cite{H1952POTIRE}. Smith et al created a Huffman Code table mapping letters of the alphabet to nucleotide strings, where the most common English letter 'e' was mapped to the nucleotide string "T", and the least common english letter 'z' was mapped to a longer nucleotide string "CCCTG". This achieved an average encoding length of 2.2 bases per letter. The mapping is unambiguous, making only one possible interpretation of each message.

Comma encoding~\cite{BVSPNAS2000} specifies that encoded words be separated by a single nucleotide (i.e., G). The remaining four (or five in Smith et al.), are composed of the other three nucleotides. Additional constraints are that only three A-T pairs are allowed, and two G-C always on the top strand, so that the DNA molecules will have isothermal melting temperatures. This technique provides particularly good detection of insertions and deletions, unfortunately it is also space inefficient.

The alternating code, also from Smith et al.~\cite{SFHC2003BL} consists of 64, 6 base pair codons, with nucleotides alternating between an A or G (purines) at odd positions, and C or T (pyrimidines) at evens (e.g., RYRYRY…, YRYRYR). Like the comma encoding, the alternating code results in isothermically stable molecules with a 1:1 ratio of A-T to G-C pairs. While more space efficient, this technique is not as proficient at error detection, as only 67\% of codons result in nonsense codons after mutation, compared to 83\% for the comma code.

Contrast mapping is an encoding scheme developed by Mousa et al.~\cite{MMAIAJI2011}. The binary message is divided into 6-bit groups, each converted to decimal (base 10). Pairs of consecutive values ($x, y$) are converted into ($x', y'$) with the the following linear transformations: $x' = 2x - y$,  $y' = 2y - x$. Values are limited to the subdomain:  0 $\leq$ 2$x - y$ $\leq$ $L$, 0 $\leq$ 2$y$ - $x$ $\leq$ $L$. Values are decoded with the following equations: $x = [3x' + 3y'], y = [3 x' + 3y']$. This technique is sufficiently flexible to be applied to DNA or image steganography.

\subsection{Artificial Encoding}

Artificial DNA encoding, or DNA data storage, is the process of storing digital information such as text, audio, or images within \textit{in vitro} DNA base pair sequences. DNA is an appealing storage medium due to its high density. For example, the human genome contains 3.3e9 base pairs, or about 725 MB of binary data, with a mass of 3.59e-12 grams. DNA is also incredibly resilient, as the sequencing of 45,000 year old woolly mammoth genomes indicate~\cite{PALKOPOULOU2015}. As with any memory device, the critical operations are read and write. Continued advances in DNA sequencing (reading) and oligonucleotide synthesis (writing) increase the viability of nucleic acid for long term archival storage.

DNA was first encoded with a secret message in 1999 by Clelland et al~\cite{CRB1999N}. Inspired by the tiny, concealed microdot messages used in World War II, artificial DNA strands were constructed using a simple substitution cipher, then mixed with human DNA and pipetted onto a printed period on filter paper. The encoded DNA was later recovered from the dot and sequenced to successfully read the secret message: JUNE 6 INVASION: NORMANDY.

The primary limiting factor has been the length of the oligonucleotides that can be synthesized. Church et al.~\cite{CHURCH2012} developed a technique using high fidelity DNA microchips to encode 5.27 MB of data including a book by the author, 11 JPEG images, and a JavaScript program into 54,898 159 nt sequences. Each 159 nt sequence consisted of a 96 nt data block and 19 nt address. The data were recovered with only 10 bit errors.

Goldman et al.~\cite{GOLDMAN2013} were able to encode 739 KB of text, images, and audio with 100\% recovery rate. The technique applied a modified Huffman code~\cite{H1952POTIRE}, converting the binary (base-2) data into ternary (base-3), and mapping each trit to a nucleotide, different from the one preceding it in order to prevent homopolymers. The sequences were capped with reverse complemented index information so that the data could be reassembled by scanning for overlaps.

Grass et al.~\cite{GRASS2015} developed error correction codes for DNA stored in silica gel and exposed to high temperature ($70^o$ C). Every two bytes of input data are mapped to three values from the Galois Field of size 47 (GF(47)). The mappings are arranged in blocks of 594\texttt{x}30. Each block also has 594\texttt{x}3 bits of index data. In the second step, Reed-Solomon (RS) codes~\cite{REED1960} are applied to add 119 bits of redundancy A. In another round of RS, a redundancy B of 6 bits in length. This results in a final block size of 713\texttt{x}39. Each column is mapped to an oligonucleotide by mapping each value from GF(47) to a DNA codon (triplet).

Yazdi et al.~\cite{YAZDI2015} also developed a random access and rewritable DNA storage system, achieved with an addressing scheme. A 1000 bp sequence represents a 960 bp block of data flanked on either side by address regions of 20 bps. The data regions are divided into 12 blocks of 80 bps each, or 6 words of input text per block. Primer sequences correspond to the address sequences, allowing for selective PCR amplification of a desired block. The binary sequences are converted into nucleotides via DNA prefix-synchronized codes. The error correction code is based on binary running digital sums (BRDS). The encoding scheme satisfies four constraints, 1) GC content of approximately 50\%, 2) large Hamming distance between any two strings of equal length, 3) uncorrelated addresses to prevent primer binding to the wrong address, and 4) absence of secondary folding structures.

Blawat et al.~\cite{BLAWAT2016} improved upon the encoding scheme of ~\cite{CHURCH2012} by developing forward error correction codes. The homopolymer restriction is relaxed somewhat by requiring that the first three nucleotides must differ, as must the last two. A block of data is contained within an oligo sequence of up to 250 bp. An error detection code (EDC) is added to each. Addresses are protected with a BCH code ~\cite{BOSE1960} and a minimum Hamming distance of 9. Consecutive oligo sequences are protected with RS code~\cite{REED1960} over GF($2^8$) with block size of 223. The EDC parity bits employe a CCITT 16 bit cyclic redundancy check (CRC) ~\cite{LIN2004}.

Bornholt et al.~\cite{BORNHOLT2016} have developed a DNA-based archival storage system that also allows for random access reading. They adopt the binary to ternary Huffman encoding technique of ~\cite{GOLDMAN2013} for storing data. Similarly to ~\cite{YAZDI2015}, each sequence has a primer target sequence on either end of the oligonucleotide. Data are stored in the payload, which is followed by the address. Following the first primer sequence and before the last is an orientation nucleotide to determine if the oligo is being read in the 5' to 3' or 3' to 5' direction. Also like ~\cite{YAZDI2015}, random access is provided by selective PCR amplification via specific primers. The overall system acts as a key-value store with primers acting as keys. Error correction is provided via redundancy, that is more important regions are sequenced in greater quantities. A simple error correction technique is achieved by performing an XOR on strands of equal length to ensure proper alignment.

\subsection{Image Steganography}

One of the inspirations of biosteganography is the practice of image steganography. The modification of the wobble codon in pcDNA encoding is analogous to the storage of information within the least significant bits (LSB) of the bytes within digital images. The concept of watermarking in particular is closely related. Image steganography can be described by three broad categories, spatial domain, frequency domain, and adaptive methods.

The target digital media is referred to as the carrier or ``cover'' image $C$, and the embedded data as the ``payload'', $M$, encoded in the stego-image $C$'. An optional key $K$ can be used to encrypt the message $M$. The function $Em$ represents embedding (analogous to encryption), and $Ex$ extraction (analogous to decryption), such that:

\[
	Ex[C'] = Ex[Em(C,K,M)] = M
\]

LSB modification falls under the spatial domain category. Up to four LSB bytes can be modified, but the image quality quickly begins to suffer, and the effects more apparent to the viewer. Potdar et al.~\cite{POTDAR2005} developed a fingerprinting technique to minimize these image cropping effects by dividing $C$ into subimages $C_i$. The success of steganography in the spatial domain is dependent on the image format. Lossless formats are ideal (e.g., BMP, PNG), while lossy formats (e.g., GIF, JPG) are less so.~\cite{JUNG2009} Histogram data hiding techniques based on the differences between adjacent pixels are less susceptible to detection.~\cite{LI2009}

Methods in the frequency domain include the discrete cosine transform (DCT)~\cite{MANIKOPOLOUS2002}, Fourier transform (FT)~\cite{MCKEON2007}, and discrete wavelet transform (DWT)~\cite{CHEN2007,POTDAR2005S,VERMA2005,ABDULAZIZ2000}. JPEG compression applies DCT to transform image sub-blocks, data can encoded into the corresponding coefficients. Detection is difficult if chosen carefully, e.g., by a genetic algorithm.~\cite{FARD2006}. Work in the DWT domain includes artificial neural networks (ANNTS)~\cite{PAULSON2006} and cover image decomposition.~\cite{ABDELWAHAB2008}

Adaptive integration is a composite of the previous two methods. Statistics are applied to automatically select the best data hiding technique. These include the model based method using the Cauchy distribution~\cite{SALLEE2003}, the LSB substitution method that estimates the degree of smoothness between adjacent pixels~\cite{CHANG2004}, block complexity based data embedding (ABCDE)~\cite{HIROHISA2002}, and genetic algorithm approaches that attempt to artificially obscure statistical features.~\cite{WU2006GEN}

\subsection{Cellular Encoding Restrictions}

Cellular DNA encoding must not harm the carrier organism, either by removing cellular functionality or adding mutative behavior. To avoid this, encoding schemes must ensure that modified DNA strands remain biologically equivalent to their wild-type form. This section defines the bio-restrictions that exist for two distinct areas of cellular DNA, protein coding DNA (pcDNA) and noncoding DNA (ncDNA). As our knowledge of genetics continues to expand, more particular restrictions may become known.

\subsubsection{pcDNA Constraints}

The protein coding region of DNA contains the codons that are translated to amino acids, which are concatenated into proteins. Any data insertions in this area must meet the following constraints.

\textit{Protein Preservation} The structure of the protein coded by the region must remain unchanged. Nucleotide insertions and modifications must not alter the codons in such a way that would change the original amino acid sequence.

\textit{Codon Bias Preservation} Individual cells have specific ratios of cytoplasmic tRNA associated with their genomic codons, which can be disrupted if the codon balance is changed, and have a negative effect on the cell. Therefore, it is important that codon bias is preserved.

\subsubsection{ncDNA Constraints}

The noncoding region of DNA is often called "junk DNA" for its apparent lack of use in the cell. Because they appear to be non-functional, data can be embedded into these regions if the following constraints are met.

\textit{Truly nonfunctional region.} When ncDNA was first discovered it was assumed to have no role in cell functionality, but recent studies have shown that up to 80\% of ncDNA may have biochemical functions in the cell, despite not coding for proteins~\cite{EPC2012N}. Therefore, it is first imperative that the individual who wishes to insert a message into ncDNA verify that they are encoding their message in the 20\% that has no biochemical use.

\textit{No start codons.} When a cell's genetic machinery locates a start codon, it can begin the transcription process. To prevent unwanted transcription from happening in ncDNA with embedded data, it is important to make sure the encoded nucleotides to not create a start codon. When a DNA string is being transcribed, three-nucleotide codons can be read in six different reading frames. Therefore, there should not be a start codon in any of the six frames. The most common start codon is AUG, though some alternative start codons can also exist, particularly in bacteria~\cite{B1997S}. If a cell contains alternative start codons, the encoding scheme should avoid all of them.

\textit{No homopolymers.} A DNA homopolymer is a region where the same nucleotide is repeated multiple times. Too many repeats can cause errors during DNA replication through polymerase slippage~\cite{VCE2001TEJ}. These replication errors could quickly distort the inserted message and possibly damage the cell after a few generations. For this reason any ncDNA encoding scheme should not include homopolymers greater than length 3.

\section{Encoding Schemes}

Encoding schemes for cellular DNA can involve several components:

\begin{enumerate}
\item Encryption algorithm
\item Mapping table
\item Compression
\item Error correction
\item Fake data embedding
\end{enumerate}

The following encoding schemes use some or all of these elements in their design.


\begin{table*}[t]
	\caption{Comparison of Encoding Schemes}
	\label{fig:table1}
	\centering
	\scalebox{0.7}{
	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}\hline \hline
		& Method  &\multicolumn{4}{|c|}{\textbf{Bio-Restrictions Satisfied}}  &\multicolumn{5}{|c|}{\textbf{Scheme Components}}\\ \hline
		  & &No Homopolymers  &No Start Codons  &Preserves Codon Bias  &Balances C-G  &Error Detection  &Error Correction  &Compression  &Encryption  &Blind Decoding\\ \hline
	\multirow{6}{*}{pcDNA} & Secret Signature~\cite{AY2004BP}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &\centering{$\CIRCLE$}  &  &  &  &\\ \hline
		&DNA-Crypt~\cite{HBBMC2007}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$} &  &  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &\centering{$\CIRCLE$}  &\\ \hline
        &Codon Usage Table~\cite{LDBKHLW2012PO}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$} &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &  &  &$\CIRCLE$\\ \hline
		&BioCode~\cite{HBBMC2013}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$} &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &\\ \hline
		&DWT Based~\cite{L2014IS}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &\\ \hline
        &LSBase~\cite{KH2015BJOMACS}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$} &  &  &  &  &  &  &$\CIRCLE$\\ \hline
        \multirow{7}{*}{ncDNA and Plasmids} &Organic Memory~\cite{WWF2003COTACM}  &  &  &\centering{$\CIRCLE$}  &  &  &  &  &  &$\CIRCLE$\\ \hline
		&Alignment-Based~\cite{YSSOT2007BP}  &  &  &\centering{$\CIRCLE$}  &  &\centering{$\Circle$}  &\centering{$\Circle$}  &  &  &$\CIRCLE$\\ \hline
		&Improved Huffman~\cite{AR2009BT}  &  &  &\centering{$\CIRCLE$}  &\centering{$\Circle$}  &  &  &\centering{$\CIRCLE$}  &  &$\CIRCLE$\\ \hline
		&RAlign~\cite{HB2011IEEEICOBAB}  &  &  &\centering{$\CIRCLE$}  &  &\centering{$\Circle$}  &\centering{$\Circle$}  &  &  &$\CIRCLE$\\ \hline
		&HTAlign~\cite{HB2011IEEEICOBAB}  &  &  &\centering{$\CIRCLE$}  &  &\centering{$\Circle$}  &\centering{$\Circle$}  &  &  &$\CIRCLE$\\ \hline
		&DNA Barcodes~\cite{KS2015BMCB}  &\centering{$\CIRCLE$}  &  &\centering{$\CIRCLE$}  &  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &$\CIRCLE$\\ \hline
		&DNA-Courier Attack~\cite{CLY2015SAPW}  &  &  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &  &\centering{$\CIRCLE$}  &$\CIRCLE$\\ \hline
	\end{tabular}}
    \fontsize{7pt}{12pt}\selectfont
    \raggedright $\Circle$ denotes partially satisfied whereas $\CIRCLE$ denotes completely satisfied.
\end{table*}

\subsection{pcDNA Encoding}

Shimanovsky et al~\cite{SFHC2003BL} were the first to propose using codon degeneracy to encode data in pcDNA. By switching codons between their redundant forms with the modification of one nucleotide, data was inserted without altering protein translation. Arita and Ohashi~\cite{AY2004BP} implemented this technique in a living cell. They did this using site-directed mutagenesis of wobble codons in the \textit{ftsZ} gene of \textit{Bacillus subtilis}. The university name "KEIO" was inserted by modifying the redundant nucleotides of the codons downstream of the \textit{ftsZ} start codon. An unmodified codon represented value 0 while a codon with a wobble nucleotide changed to any of its non-wild type redundant forms represented value 1. Messages were translated using a 6-bit mapping table, with the first 5 bits corresponding to an English alphabet letter or basic punctuation, and the last used as a parity bit for error correction.

Heider et al. developed the DNA-Crypt~\cite{HBBMC2007} algorithm for creating DNA watermarks for marking genetically modified organisms. It is similar to the work of Arita et al. in that the encoding targets the wobble base pair in the genetic code. An encryption function $E$ maps the plaintext (binary data) $X$ to the ciphertext (genetic data) $Y$, such that $X \in  \{$0, 1$\}$ and $Y \in \{$A, C, G, T$\}$. Two bits are encoded per base, or one byte for four bases. Error correction is achieved with a fuzzy controller that selects one of two algorithms, either the 8/4 Hamming code for mutations that differ in only bit (e.g., 00 to 01) or the WDH-code for those that differ by multiple bits. This encoding scheme allowed implementations of several cryptographic algorithms, including One-Time Pad, AES, Blowfish, and RSA. The accuracy was tested using the GTPase encoding Ypt gene in $S. cerevisiae$.

Liss et al. were the first to design a pcDNA encoding scheme that allowed for blind decoding~\cite{LDBKHLW2012PO}. First a codon usage table was created, which ranked synonymous codons according to their natural occurrence. An odd-ranked codon (1st, 3rd, or 5th) represented binary 1, while an even-ranked codon (2nd, 4th, or 6th) represented binary 0. Encoding in this way also allowed for codon bias preservation through gene optimization. The receiver who obtains the DNA would only need to know which gene had the encoded message, and the codon usage table, which itself could be encoded into the same genome. Since the receiver does not need to know the wildtype sequence of the genome to decode, this type of scheme can be blindly decoded.

Another blind technique for pcDNA, LSBase, was developed by Khalifa and Hamad ~\cite{KH2015BJOMACS}. Their scheme used a very simple mapping table that allowed for easy encoding and blind decoding. For every wobble codon in the encoding region, the use of a U or an A in the least significant base represented bit 0 while a C or a G represented bit 1. The researchers were able to test their scheme in silico, and found a high bits per nucleotide capacity (0.333) compared to other schemes. However, no effort was made to account for codon bias preservation.

Haughton and Balado proposed BioCode~\cite{HBBMC2013}, a pair of encoding algorithms, one for ncDNA, and one for pcDNA. The ncDNA algorithm expands upon DNA-Crypt by observing the no start codons in restriction. This is accomplished by defining a set of dinucleotides $D$ = $\{$ AT, CT, TT, CA $\}$ that covers the possible eukaryotic start codons on either DNA strand. The trailing dinucleotide $d$ is continually checked for membership in $D$. If found, $d$ is replaced with a lookup table formed from a graduated mapping of the message space $M_d$ to set $S_d$. The pcDNA encoding technique is similar, but enforces the additional constraint of Binary Codon Equivalency (BCE). This requires that the cardinality of the codon set (|$S_d$|) be varied during the embedding process to allow the usage of a static lookup table.

In order to better preserve codon bias, Lee developed a discrete wavelet transform (DWT) technique for pcDNA encoding~\cite{L2014IS}. The target coding sequence was divided into subsequences in which every codon was given a numerical code associated with amino acid histogram rankings. DWT coefficients were calculated for synonymous codons and the optimal subsequence was found, which was then replaced with the encoded subsequence. A nonlinear congruential-pseudorandom number generator then created the watermark and picked the location in the DWT domain for embedding.

\subsection{ncDNA and Plasmid Encoding}

The development of encoding schemes for ncDNA and plasmids have been strongly correlated, due to two regions having nearly identical bio-restrictions. The main difference being that plasmid encoding is also confined by length. However, due to their similarities and the parallel advancement of their encoding schemes, we will consider them both in this section.

~\cite{WWF2003COTACM} were the first to encode data into plasmids. Letters and punctuation were mapped to nucleotide triplets, then short text snippets of 19 to 33 characters were inserted into the plasmids of Deinococcus radiodurans, a bacteria that is very resilient to extreme conditions. The encoded section of the plasmid was flanked by sentinel sequences 20 base pairs long containing stop codons. This was done to prevent the bacteria from transcribing the message while reading the adjacent functional parts of the plasmid. After insertion of the plasmids into the host bacteria, they were incorporated into their genomes. No error correction, encryption, or compression techniques were used.

~\cite{YSSOT2007BP} came up with the idea of using multiple alignment in lieu of error detection or correction techniques. With this scheme, messages were composed using the Keyboard Scan Code Set2, which contains all keyboard inputs, and converted these messages to binary. The encryption keys mapped four bits of binary code to two nucleotides. This type of mapping created four reading frames in the binary message (C1 - C4), each of which was converted to DNA and inserted adjacently into the plasmid, creating redundancy that allowed for multiple alignment when decoding.

Repetition coding was used again, this time for ncdDNA, by ~\cite{HB2011IEEEICOBAB} who used two variant approaches. Both approaches required finding subsequences in the host ncDNA equal to the length of the encoded message, and replacing them with the message, as opposed to simply inserting the message and expanding the DNA strand. With the first approach, $RAlign$, the redundant subsequences were each prepended and appended with unique 24-bp long markers to aid alignment, and replaced specific subsequences in the genome that were known by both the sender and receiver. With the second approach, $HTAlign$, the prepended and appended markers were identical, which means the receiver does not need to know the location of the replaced subsequences, but can find the repeated messages by searching for the markers alone.

Wanting to improve on the very low bits per base density of previous schemes, Ailenberg and Rotstein suggested an improved Huffman code that could decrease the sequence sizes by up to 40\%~\cite{AR2009BT} compared to other schemes. Keyboard characters were mapped to variable length sequences, with the more common characters assigned to the shorter sequences. To help maintain C-G balance, CG-rich codons were pushed downwards on the frequency table. To illustrate the density that could be achieved, text and musical notes for "Mary Had a Little Lamb", along with an image of a lamb made with geometric shapes, were encoded into a mere 844-bp DNA fragment. It was estimated that this encoding scheme would average 3.5 bases-per-character, which was a noted improvement over previous schemes. No error correction was used.

~\cite{HPB2009BMCRN} were interested in the possibility of encoding data in non-protein coding but biochemically functional DNA. 2-3 character watermarks were inserted into non-coding promoter regions and a regulatory RNA region in $Escherichia coli$. The introduction of the watermarks were shown to disrupt the reading of the genes associated with the promoters and changed the secondary structure of the regulatory RNA molecule. This research was significant in showing that biochemically functional ncDNA is a poor region for encoding.

~\cite{CLY2015SAPW} were the first to design a cyber attack model they named "DNA courier attack" using encoded DNA. To ensure secrecy, the message was first encrypted into ciphertext using the encryption algorithm AES-128 with a secret key. Then a probability distribution of the DNA fragments in the non-coding regions was created. The mapping table was formed by sorting the codons and 5-bit sequences by frequency and matching the two directly. After insertion of the message, fake data was then embedded to rebalance the original codon distribution and further hide the message data. The encoded sequence is then inserted into an isolated plasmid, which is injected into a bacterial cell that can multiply and be hidden so the sender can carry it through a tight security checkpoint if necessary.

%\begin{table*}[t]
%	\caption{Details of Encoding Schemes}
%	\label{fig:table2}
%	\centering
%	\scalebox{0.9}{
%	\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}\hline \hline
%		 &Scheme &Organism &Storage Site &Method &Data  &Density $^\dagger$ &Error Detection/Correction \\ \hline
%	\multirow{1}{*}{\vspace{0cm}\textbf{pcDNA}} & Secret Signature  &Bacillus subtilis  &ftsZ gene &Mutan-Super Express &"KEIO"  &0.05 cpn &Parity bit \\ \hline
%		&DNA-Crypt &S. cerevisiae  &Ypt7 gene &In silico  &"this is a test"  &variable &Hamming or WDH\\ \hline
%        &Codon Usage Table  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$} &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &  &  &$\CIRCLE$\\ \hline
%		&BioCode  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$} &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &\\ \hline
%		&DWT Based  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &\\ \hline
%        \multirow{1}{*}{\vspace{0cm}\textbf{ncDNA and Plasmids}} &Organic Memory  &  &  &\centering{$\CIRCLE$}  &  &  &  &  &  &$\CIRCLE$\\ \hline
%		&Alignment-Based &  &  &\centering{$\CIRCLE$}  &  &\centering{$\Circle$}  &\centering{$\Circle$}  &  &  &$\CIRCLE$\\ \hline
%		&Improved Huffman  &  &  &\centering{$\CIRCLE$}  &\centering{$\Circle$}  &  &  &\centering{$\CIRCLE$}  &  &$\CIRCLE$\\ \hline
%		&RAlign  &  &  &\centering{$\CIRCLE$}  &  &\centering{$\Circle$}  &\centering{$\Circle$}  &  &  &$\CIRCLE$\\ \hline
%		&HTAlign  &  &  &\centering{$\CIRCLE$}  &  &\centering{$\Circle$}  &\centering{$\Circle$}  &  &  &$\CIRCLE$\\ \hline
%		&DNA Barcodes  &\centering{$\CIRCLE$}  &  &\centering{$\CIRCLE$}  &  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &$\CIRCLE$\\ \hline
%		&DNA-Courier Attack  &  &  &\centering{$\CIRCLE$}  &\centering{$\CIRCLE$}  &  &  &  &\centering{$\CIRCLE$}  &$\CIRCLE$\\ \hline
%	\end{tabular}}
%    \vspace{0.01cm}
%    \newline
%    $\dagger$
%    \fontsize{7pt}{12pt}\selectfont
%    \raggedright In this column, cpn denotes "characters per nucleotide" and bpn denotes "bits per nucleotide", representing the two kinds of mapping tables used.
%\end{table*}

\section{Gaps and Future Directions}

There are several other aspects of DNA that have seen little research for biosteganography, but have substantial importance for message encoding and watermarking. We illuminate how these areas deserve further research in this section.

\subsection{Addressing}

Artificial DNA researchers have already taken advantage of data addressing to effectively access random data sections in encoded synthetic DNA and also update those sections with new data~\cite{SG2016BRI}. This useful technique has yet to be implemented in cellular DNA, and should be a primary direction of future research. With addressing, a lengthy message could be split up and inserted into multiple parts of a genome, taking advantage of pcDNA, ncDNA, and plasmids simultaneously.

\subsection{Memory Limits}

Currently, the largest amount of data inserted in to cellular DNA has been 844 base pairs~\cite{AR2009BT}. Most organisms have genomes numbering in the billions of base pairs, which begs the question of how much encoded data can cells safely maintain? And how would those maximum lengths differ between organisms?

The DNA substitutions in pcDNA schemes could hypothetically be done in every pcDNA region, but insertions into ncDNA have a limit. If a DNA strand is expanded too far beyond it's normal length, cellular disruption could occur. But so far that limit has not been tested in any genome.

The problem of single lengthy insertions could be avoided by using addressing techniques mentioned previously. If the data of a long insertion were dispersed to multiple parts of the genome and accessed via addressing, much more data could be inserted into the genome. So the question of memory limits is twofold: 1.) How much can be inserted into single regions? and 2.) How much data can be safely inserted into a genome as a whole? Knowing the limitations for different organisms would be invaluable knowledge as the technology for cellular DNA modification continues to develop.


\subsection{Compression}

Advances in cellular DNA encoding have so far been made using short messages. Therefore, the need for compression techniques has been minimal. Compression also creates additional difficulties because it allows mutative errors to cause more disruption to the data. But we believe that if cellular DNA is to become a more viable method of secure data encoding, more research must be done into methods that compress data while at the same time reducing damage from errors.

The clearest way to accomplish this is with compression matched with error correction. The DNA-Crypt algorithm implements a fuzzy controller that determines what type of error correction is best for optimal performance given mutation rate, sequence length, and stability~\cite{HBBMC2007}. We believe a similar sort of fuzzy controller could be used determine ideal error correction methods by adding an additional parameter for compression density.

Both compression and error correction are already being used widely in artificial DNA encoding. Many of those techniques could be transferred to cellular DNA encoding with little to no changes. Compression would be particularly useful for transferring large private messages in cellular DNA. For the purposes of watermarking, it may not be necessary. But due to the lack of implementation in the literature and the clear usefulness of compression, we believe it is one of the most important directions future research should take.

\subsection{Mitochondrial DNA}

Heider et al.~\cite{HKB2008B} suggested using mitochondria for secret data encoding. Mitochondria are organelles in the cell that contain a small amount of DNA that encodes translation machinery and oxidative chain components~\cite{GV2001G}. Heider et al. identified an mtDNA section 1,541 base pairs long that contains no active gene regions and suggested that it would be an ideal location for embedding data with synonymous codons. They created a program called $Project Mito$, derived from $DNA-Crypt$, that encrypts binary files and modifies them with the Hamming code for error correction, before translating the message into an mtDNA sequence. $Project Mito$ can also be used for decryption after the DNA is sequenced. $Project Mito$ inserts data into the Cytochrome c oxidase subunit I gene, allowing for the insertion of up to 60 bytes.

Since the development of $Project Mito$, little research has been done on Mitochondrial DNA encoding, and the tool itself has seen little use by other researchers. The potential for mitochondrial encoding is still largely untapped, and should be an important focus for future research. Mitochondria contain genes for both proteins and tRNA. The tRNA genes, due to their unique functionality in the cell, may have slightly different bio-restrictions than the protein coding genes. Designing encoding schemes to meet tRNA gene restrictions is another avenue worthy of research.

\subsection{Methylation Encoding}

Methylation is the process by which cells repress the expression of their own genes by attaching methyl groups to specific adenine and cytosine nucleotides of those genes~\cite{RRBW2006B}. Methylation is maintained after cell division by a family of enzymes known as DNA methyltransferase. Because the cell can preserve these methyl groups even after replicating, the authors of this survey would like to propose encoding via methylation as a completely new form of DNA encoding.

If the sender and receiver can agree on a specific start location in junk DNA for the message, the data can be encoded in binary via methylation. For every cytosine (and adenine for bacteria and plants) found after the start location, the presence of a methyl group represents bit 1 while the absence of a methyl group indicates bit 0. If the receiver of the message had an easy way to read the methyl groups ahead of the site, it would be trivial for them to decode the embedded data.

This technique of methylation encoding would be restricted only by the insertion location. If the embedding site is in truly non-functional ncDNA, the encoder does not need to be concerned about the other bio-restrictions associated with ncDNA. This would allow for raw binary encoding without the need for complex algorithms and schemes to get around the common bio-restrictions.

While the technology for site-specific methylation is still in its infancy, we can expect that soon the ability to encode and read methyl groups in DNA will be more available and economical. When this happens, we believe methylation encoding could become one of the most efficient and useful forms of cellular DNA encoding.

\bibliographystyle{natbib}
\bibliographystyle{achemnat}
\bibliographystyle{plainnat}
\bibliographystyle{abbrv}
\bibliographystyle{bioinformatics}

\bibliographystyle{plain}

\bibliography{document}



\end{document}
